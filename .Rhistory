tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
}
points <- data.frame(score=score, review=review, writer=writer, time=time)
df_points <- rbind.data.frame(df_points, points)
}
library(rvest)
library(stringr)
library(dplyr)
library(xlsx)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
url_base <- 'https://movie.naver.com'
start_url <- '/movie/bi/mi/point.nhn?code=61521'
url <- paste0(url_base, start_url)
html <- read_html(url)
html %>%
html_node('iframe.ifr') %>%
html_attr('src') -> if_url
ifr_url <- paste0(url_base, if_url)
html2 <- read_html(ifr_url)
html2 %>%
html_node('div.score_total') %>%
html_nodes('em') -> ems
pages <- ems[2] %>% html_text()
pages <- gsub(",", "", pages)
total_page <- ceiling(as.numeric(pages)/10)
html2 %>%
html_node('div.paging') %>%
html_node('a') %>%
html_attr('href') -> tmp
page_url_base <- str_sub(tmp, 1, -2)
df_points <- data.frame(score=c(), review=c(), writer=c(), time=c())
for (i in 1:total_page) {
if (i %% 100 == 0)
print(i)
page_url <- paste0(url_base, page_url_base, i)
html <- read_html(page_url)
html %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
score <- c()
review <- c()
writer <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> tmp
idx <- str_locate(tmp, "\r")
rev <- str_sub(tmp, 1, idx[1]-1)
#print(rev)
review <- c(review, rev)
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
}
points <- data.frame(score=score, review=review, writer=writer, time=time)
df_points <- rbind.data.frame(df_points, points)
}
points <- data.frame(score=score, review=review, writer=writer, time=time)
df_points <- rbind.data.frame(df_points, points)
df_points
View(df_points)
write.csv(df_points)
write.csv(df_points,file = "트포")
write.csv(df_points,file = "트포".csv)
write.csv(df_points,file = "트포")
write.csv(df_points,"D:/Workspace/data.csv")
read.csv(data)
read.csv(datata)
read.csv(datata)
read.csv(datata)
read.csv(datata)
read.csv("과제")
library(utils)
read.csv("과제")
read.csv(gaga)
read.csv(gaga, header = T)
read.csv(gaga, header = T)
read.csv(gaga, header = T)
read.csv("gaga", header = T)
read.csv("gaga")
read.csv("D:/Workspace/R-Statistics/gaga.csv")
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data
View(data)
View(data)
data[,2]
data[,3]
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP")
library(rJava)
library(memoise)
library(KoNLP)
library(dplyr)
txt <- readLines("data1")
txt <- readLines(data1)
data1 <- data[,3]
txt <- readLines(data1)
data1
install.packages("stringr")
install.packages("stringr")
library(stringr)
txt <- str_replace_all(data1, "\\W", " ")
txt
class(data1)
useNIADic()
txt <- readLines(data1)
data1
class("data1")
txt <- readLines("data1")
txt <- str_replace_all(data1, "\\W", " ")
txt
nouns <- extractNoun(txt)
nouns
reviews <- repair_encoding(data1, from = 'utf-8')
library(rvest)
library(httr)
library(tm)
library(qgraph)
library(xml2)
install.packages("tm")
install.packages("qgraph")
library(tm)
library(qgraph)
library(xml2)
reviews <- repair_encoding(data1, from = 'utf-8')
if( length(reviews) == 0 ){ break
if( length(reviews) == 0 ){ break }
if( length(reviews) == 0 ){ break }
reviews <- str_trim(reviews)
reviews
reviews <- repair_encoding(txt, from = 'utf-8')
reviews
if( length(reviews) == 0 ){ break }
reviews <- str_trim(reviews)
reviews
install.packages("gtable")
install.packages("gtable")
library(gtable)
install.packages("hmm")
install.packages("HMM")
library(HMM)
spacing(hmm, reviews)
install.packages("gtable_add_space")
install.packages("gtable")
install.packages("gtable")
library(gtable)
spacing(hmm, reviews)
install.packages("spacing")
install.packages("devtools")
install.packages("devtools")
library(devtools)
spacing(hmm, reviews)
install_github("youngwoos/kospacing")
library(youngwoos/kospacing)
library(kospacing)
library(youngwoos)
spacing(hmm, reviews)
spacing(hmm, 오늘은정말최고야)
spacing(hmm, 오늘은정말최고야)
spacing(hmm, "오늘은정말최고야")
spacing("오늘은정말최고야")
spacing(c("오늘은정말최고야"))
spacing("오늘은정말최고야")
spacing("아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
spacing()
spacing("acv")
spacing("아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
library(devtools)
library(kospacing)
spacing("아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
library(stringr)
library(rJava)
library(memoise)
library(KoNLP)
library(dplyr)
library(rvest)
library(httr)
library(tm)
library(qgraph)
library(xml2)
library(gtable)
library(HMM)
library(devtools)
library(kospacing)
spacing("아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
library(utils)
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data1 <- data[,3]
class("data1")
data1 <- data[,3]
class("data1")
data1
library(stringr)
library(rJava)
library(memoise)
library(KoNLP)
library(dplyr)
library(rvest)
library(httr)
library(tm)
library(qgraph)
library(xml2)
library(gtable)
library(HMM)
library(devtools)
library(kospacing)
spacing("아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
txt <- str_replace_all(data1, "\\W", " ")
txt
if( length(reviews) == 0 ){ break }
reviews <- repair_encoding(txt, from = 'utf-8')
if( length(reviews) == 0 ){ break }
reviews
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data1 <- data[,3]
class("data1")
txt <- repair_encoding(data1, from = 'utf-8')
txt
data1
txt1 <- str_replace_all(data1, "\\W", " ")
txt1
library(kospacing)
spacing("dfd")
readLines(txt1)
install.packages('tidyverse')
library(tidyverse)
readLines(txt1)
write.table(data1, "D:/Workspace/R-Statistics/gaga.txt")
dat <-  write.table(data1, "D:/Workspace/R-Statistics/gaga.txt")
dat
write.table(data1, "D:/Workspace/R-Statistics/gaga.txt")
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data1 <- data[,3]
data1
write.table(data1, "D:/Workspace/R-Statistics/gaga.txt")
data2<- read.table("gaga.txt",header = TRUE)
data2
View(data2)
txt1 <- str_replace_all(data2, "\\W", " ")
data1 <- data[,3]
write.table(data1, "D:/Workspace/R-Statistics/gaga.txt")
data2<- read.table("gaga.txt",header = TRUE)
txt1 <- str_replace_all(data2, "\\W", " ")
readLines(data2)
reviews <- str_trim(reviews)
reviews <- str_replace_all(data2, "\\W", " ")
reviews <- str_replace_all(data1, "\\W", " ")
reviews
reviews <- str_trim(reviews)
reviews
reviews <- str_replace_all(data1, "\\W", " ")
reviews
nouns <- extractNoun(txt)
nouns <- extractNoun(reviews)
nouns <- sapply(reviews, extractNoun, USE.NAMES=F)
nouns
head(unlist(nouns), 30)
nouns1 <- unlist(data2)
nouns1
View(nouns)
nouns1 <- unlist(data2)
nouns1
nouns <- sapply(reviews, extractNoun, USE.NAMES=F)
nouns
head(unlist(nouns), 30)
nouns1 <- Filter(function(x) {nchar(x) <= 10}, nouns)
nouns1
nouns1 <- Filter(function(x) {nchar(x) >= 1}, nouns)
nouns1
nouns <- extractNoun(reviews)
nouns
head(unlist(nouns), 30)
nouns1 <- Filter(function(x) {nchar(x) <= 10}, nouns)
nouns1 <- Filter(function(x) {nchar(x) >= 1}, nouns1)
nouns1
head(unlist(nouns), 30)
nouns1 <- unlist(nouns)
nouns1
head(unlist(nouns), 30)
nouns1 <- Filter(function(x) {nchar(x) <= 10}, nouns1)
nouns1 <- Filter(function(x) {nchar(x) >= 1}, nouns1)
head(unlist(nouns1), 30)
nouns1
head(unlist(nouns1), 30)
nouns1
nouns1 <- Filter(function(x) {nchar(x) <= 10}, nouns1)
nouns1 <- Filter(function(x) {nchar(x) >= 2}, nouns1)
head(unlist(nouns1), 30)
library(ggplot2)
ggplot(nouns1)
nouns1
nouns2 <- gsub("\\d+", "", nouns1)
nouns2
nouns2 <- gsub(" ", "", nouns2)
nouns2
nouns3 <- str_replace_all(nouns2, "\\W", " ")
nouns3
table(nouns2)
data5 <- table(nouns2)
ggplot(data5)
nouns2 <- gsub("\\d+", "", nouns1)
nouns2 <- gsub(" ", "", nouns2)
nouns2 <- gsub('[ㄱ-ㅎ]','',nouns2)
nouns2 <- gsub('[~!@#$%&*()_+=?<>]','',nouns2)
nouns2 <- gsub('(ㅜ|ㅠ)','',nouns2)
data5 <- table(nouns2)
data5
nouns2 <- gsub('^','',nouns2)
data5 <- table(nouns2)
data5
data5 <- table(nouns2)
data5
nouns2 <- gsub("\\d+", "", nouns1)
nouns2 <- gsub(" ", "", nouns2)
nouns2 <- gsub('[ㄱ-ㅎ]','',nouns2)
nouns2 <- gsub('[~!@#$%&*()_+=?<>]','',nouns2)
nouns2 <- gsub('(ㅜ|ㅠ)','',nouns2)
nouns2 <- gsub('^','',nouns2)
data5 <- table(nouns2)
data5
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data1 <- data[,3]
reviews <- str_replace_all(data1, "\\W", " ")
reviews <- str_trim(reviews)
nouns <- extractNoun(reviews)
nouns1 <- unlist(nouns)
nouns1
head(unlist(nouns1), 30)
nouns1 <- gsub("\\d+", "", nouns1)
nouns1 <- gsub(" ", "", nouns1)
nouns1 <- gsub('[ㄱ-ㅎ]','',nouns1)
nouns1 <- gsub('[~!@#$%&*()_+=?<>]','',nouns1)
nouns1 <- gsub('(ㅜ|ㅠ)','',nouns1)
nouns1 <- gsub('^','',nouns1)
nouns3 <- Filter(function(x) {nchar(x) <= 10}, nouns2)
nouns3 <- Filter(function(x) {nchar(x) >= 2}, nouns3)
nouns2 <- Filter(function(x) {nchar(x) <= 10}, nouns1)
nouns2 <- Filter(function(x) {nchar(x) >= 2}, nouns2)
data5 <- table(nouns2)
data5
nouns1 <- gsub("\\d+", "", nouns1)
nouns1 <- gsub(" ", "", nouns1)
nouns1 <- gsub('[ㄱ-ㅎ]','',nouns1)
nouns1 <- gsub('[~!@#$%&*()_+=?<>^]','',nouns1)
nouns1 <- gsub('(ㅜ|ㅠ)','',nouns1)
nouns1 <- gsub('^','',nouns1)
nouns2 <- Filter(function(x) {nchar(x) <= 10}, nouns1)
nouns2 <- Filter(function(x) {nchar(x) >= 2}, nouns2)
data5
head(unlist(nouns1), 30)
nouns2 <- gsub("\\d+", "", nouns1)
nouns2 <- gsub(" ", "", nouns2)
nouns2 <- gsub('[ㄱ-ㅎ]','',nouns2)
nouns2 <- gsub('[~!@#$%&*()_+=?<>^]','',nouns2)
nouns2 <- gsub('(ㅜ|ㅠ)','',nouns2)
nouns2 <- gsub('^','',nouns2)
nouns2 <- Filter(function(x) {nchar(x) <= 10}, nouns1)
nouns2 <- Filter(function(x) {nchar(x) >= 2}, nouns2)
data5 <- table(nouns2)
nouns3 <- Filter(function(x) {nchar(x) <= 10}, nouns2)
nouns3 <- Filter(function(x) {nchar(x) >= 2}, nouns3)
data5 <- table(nouns2)
data5
install.packages("wordcloud2")
library(wordcloud2)
wordcloud2(data5)
nouns2 <- gsub("\\d+", "", nouns1)
nouns2 <- gsub(" ", "", nouns2)
nouns2 <- gsub('[ㄱ-ㅎ]','',nouns2)
nouns2 <- gsub('[~!@#$%&*()_+=?<>^]','',nouns2)
nouns2 <- gsub('(ㅜ|ㅠ)','',nouns2)
nouns2 <- gsub('^','',nouns2)
nouns2 <- gsub('영화','',nouns2)
nouns3 <- Filter(function(x) {nchar(x) <= 10}, nouns2)
nouns3 <- Filter(function(x) {nchar(x) >= 2}, nouns3)
data5 <- table(nouns2)
wordcloud2(data5)
data5 <- table(nouns3)
wordcloud2(data5)
data5
nouns4 <- Filter(function(x) {nchar(x) >= 100}, nouns5)
nouns4 <- Filter(function(x) {nchar(x) >= 100}, data5)
nouns4
data6 <- arrange(data5)
rev <- read.table(data5)
data.frame(data5)
data6 <- data.frame(data5)
arrange(data6, data6$Freq)
data7 <- arrange(data6, data6$Freq)
data7
data7 <- arrange(data6, desc(data6$Freq))
data7
data8 <- filter(data7$Freq >=10)
class(data7$Freq)
data7 <- arrange(data6, desc(data6$Freq))
data7
head(data7, 1000)
data8 <- head(data7, 1000)
data8
wordcloud2(data8)
data2
write.table(data1, "D:/Workspace/R-Statistics/gaga.txt")
data2<- read.table("gaga.txt",header = TRUE)
data2
data <- read.csv("D:/Workspace/R-Statistics/gaga.csv")
data
View(data)
head(data)
a1 <- data[,c("score","time")
a1 <- data[,c("score","time")]
a1
class(a1$time)
str_sub(a1$time,-5,-1)
a1$time1 str_sub(a1$time,-5,-1)
a1$time1<- str_sub(a1$time,-5,-1)
a1
a1$week1<- str_sub(a1$time,10,1)
a1
a1$week1<- str_sub(a1$time,10,1)
a1$week1
a1$week1<- str_sub(a1$time,10)
a1$week1
a1$time
a1$week1<- str_sub(a1$time,10,0)
a1$week1
a1$week1<- str_sub(a1$time,10,1)
a1$week1
a1$week1<- str_sub(a1$time,10,1)
a1$week1<- str_sub(a1$time,10)
a1$week1
a1$time1
a1$week1<- str_sub(a1$time, end = -10)
a1$week1
a1$week1<- str_sub(a1$time, end = -12)
a1$week1
a1$week1<- str_sub(a1$time, end = -7)
a1$week1
head(a1)
a2 <- a1[,c("score","week1","time1")]
a2
class(a2$score)
class(a2$week1)
class(a2$time1)
a2$score <- as.numeric(a2$score)
a2$score <- as.character(a2$score)
source('D:/Workspace/r-project/01_Crawling/과제[1].R', encoding = 'UTF-8', echo=TRUE)
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP")
install.packages("stringr")
install.packages("tm")
install.packages("qgraph")
install.packages("gtable")
install.packages("HMM")
install.packages("devtools")
install.packages("tidyverse")
install.packages("wordcloud2")
install.packages("memoise")
install.packages("KoNLP")
install.packages("stringr")
install.packages("tm")
install.packages("qgraph")
install.packages("gtable")
install.packages("HMM")
install.packages("devtools")
install.packages("tidyverse")
install.packages("wordcloud2")
install.packages("tm")
install.packages("qgraph")
install.packages("gtable")
install.packages("HMM")
install.packages("devtools")
install.packages("tidyverse")
install.packages("wordcloud2")
a2$score <- as.numeric(a2$score)
a2$score <- as.character(a2$score)
a2$score <- as.character(a2$score)
a2$score <- as.numeric(a2$score)
a2$score
class(a2$score)
as.Date(a2$week1,"%y-%m-%d")
a2$week1
as.Date(a2$week1,"%y.%m.%d")
class(a2$week1)
as.numeric(a2$week1)
class(a2$week1)
strptime(a2$week1, "%Y.%m.%d")
class(a2$time1)
head(a2)
strptime(a2$time1, "%hour:%min")
strptime(a2$time1, "%H:%M")
strptime(a2$time1, "%H:%M")
as.Date(a2$time1, "%H:%M")
as.Date(a2$time1, "%H:%M")
strptime(a2$time1, "%H:%M")
fo <- strptime(a2$time1, "%H:%M")
fo
fo<- str_sub(fo, end = -7)
fo
